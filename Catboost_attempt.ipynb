{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, mean_squared_error, mean_absolute_error, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data for training\n",
    "[back to table of contents](#contents)\n",
    "\n",
    "Selecting features for the model, scaling and train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING = {\n",
    "    'Continental': 1,\n",
    "    'Transitional': 2,\n",
    "    'Marine': 3,\n",
    "}\n",
    "\n",
    "\n",
    "def add_features(df, half_window=5):\n",
    "    for feature in ['GR', 'RT', 'CN', 'DEN']:\n",
    "        for i in range(1, half_window+1):\n",
    "            df[f'{feature}_{-i}'] = 0.0\n",
    "            df[f'{feature}_{i}'] = 0.0 \n",
    "        df.loc[:, f'{feature}_mean'] = 0.0\n",
    "        \n",
    "        for well in set(df.WELL):            \n",
    "            for i in range(1,half_window+1):\n",
    "                df.loc[:, f'{feature}_{-i}'][df.WELL==well] = df[df.WELL==well][feature].shift(-i, fill_value=df[df.WELL==well][feature].iloc[-1])\n",
    "                df.loc[:, f'{feature}_{i}'][df.WELL==well] = df[df.WELL==well][feature].shift(i, fill_value=df[df.WELL==well][feature].iloc[0])   \n",
    "\n",
    "            df.loc[:, f'{feature}_mean'][df.WELL==well] = df[df.WELL==well][feature].rolling(2*half_window+1, 1, True).mean()\n",
    "\n",
    "    df['D_Env'] = df['DEPOSITIONAL_ENVIRONMENT'].apply(lambda x: MAPPING[x])\n",
    "    df['GRm/RTm'] = df['GR_mean']/df['RT_mean']\n",
    "    df['RTm/CNm'] = df['RT_mean']/df['CN_mean']\n",
    "    df['RTm/DENm'] = df['RT_mean']/df['DEN_mean']\n",
    "    \n",
    "    return df, sorted(list(set(df.columns)-set(['WELL',\n",
    "                                     'X',\n",
    "                                     'Y',\n",
    "                                     'DEPOSITIONAL_ENVIRONMENT',\n",
    "                                     'LITH_NAME',\n",
    "                                     'LITH_CODE'])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Train-dataset.csv')\n",
    "df, features_names = add_features(df)\n",
    "\n",
    "X = df[features_names]\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "y = df['LITH_CODE'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('Train-dataset.csv')\n",
    "# df, features_names = add_features(df)\n",
    "\n",
    "# # best_features = sorted(tmp_mean.values.tolist(), key=lambda x: -x[1])[:15]\n",
    "# # best_features = [f[0] for f in best_features]\n",
    "# best_features = ['GR',\n",
    "#  'MD',\n",
    "#  'DEN',\n",
    "#  'RT',\n",
    "#  'DEN_1',\n",
    "#  'GR_mean',\n",
    "#  'GR_-1',\n",
    "#  'RT_-1',\n",
    "#  'DEN_mean',\n",
    "#  'GR_5',\n",
    "#  'D_Env',\n",
    "#  'DEN_-2',\n",
    "#  'RTm/DENm',\n",
    "#  'GRm/RTm',\n",
    "#  'DEN_-1'\n",
    "# ]\n",
    "\n",
    "# features_names = best_features\n",
    "\n",
    "# X = df[best_features]\n",
    "# scaler = preprocessing.StandardScaler().fit(X)\n",
    "# X = scaler.transform(X)\n",
    "# y = df['LITH_CODE'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = []\n",
    "\n",
    "# for turn_i in range(10):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=turn_i*10)\n",
    "\n",
    "#     ros = RandomOverSampler()\n",
    "#     _, _ = ros.fit_resample(X_train, y_train)\n",
    "#     train_idx = ros.sample_indices_\n",
    "#     _, _ = ros.fit_resample(X_test, y_test)\n",
    "#     val_idx = ros.sample_indices_\n",
    "    \n",
    "#     x_train, x_val = X_train[train_idx], X_test[val_idx]\n",
    "#     y_train, y_val = y_train[train_idx], y_test[val_idx]\n",
    "    \n",
    "# #     x_train, x_val = X_train, X_test\n",
    "# #     y_train, y_val = y_train, y_test\n",
    "    \n",
    "    \n",
    "#     model = CatBoostClassifier(iterations=50, verbose=False, random_state=turn_i*10)\n",
    "#     model.fit(x_train, y_train)\n",
    "#     val_pred = model.predict(x_val)\n",
    "    \n",
    "#     tr_mmap = f1_score(y_train, model.predict(x_train), average='weighted')\n",
    "#     tr_wmap = f1_score(y_train, model.predict(x_train), average='macro')\n",
    "#     tst_mmap = f1_score(y_val, model.predict(x_val), average='weighted')\n",
    "#     tst_wmap = f1_score(y_val, model.predict(x_val), average='macro')\n",
    "\n",
    "#     models.append(model)\n",
    "# #     model.save_model(f\"model_{turn_i}.cbm\")\n",
    "#     print(f'Turn: {turn_i} tr_mmap: {tr_mmap:.3f} tst_mmap: {tst_mmap:.3f} tr_wmap: {tr_wmap:.3f} tst_wmap: {tst_wmap:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp_mean = np.stack([model.feature_importances_ for model in models]).mean(axis=0)\n",
    "# imp_0 = models[0].feature_importances_\n",
    "\n",
    "# tmp_mean = pd.DataFrame(data=[\n",
    "#     [features_names[i], imp_mean[i]] for i in range(len(features_names))], columns=['name', 'importance'])\n",
    "\n",
    "# sorted(tmp_mean.values.tolist(), key=lambda x: -x[1])[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = []\n",
    "# for model in models:\n",
    "#     predictions.append(model.predict(x_val))\n",
    "    \n",
    "# y_pred = mode(np.stack(predictions), 0).mode.reshape(-1)\n",
    "# f1_score(y_val, y_pred, average='weighted'), f1_score(y_val, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for turn_i in tqdm(range(10)):\n",
    "    ros = RandomOverSampler()\n",
    "    _, _ = ros.fit_resample(X, y)\n",
    "    train_idx = ros.sample_indices_\n",
    "    \n",
    "    x_train = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "    \n",
    "    model = CatBoostClassifier(iterations=100, verbose=False, random_state=turn_i*10)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('Validation-dataset.csv')\n",
    "df_test, _ = add_features(df_test) # features_names may have benn modified\n",
    "X_pred = scaler.transform(df_test[features_names])\n",
    "\n",
    "predictions = []\n",
    "for model in models:\n",
    "    predictions.append(model.predict(X_pred))\n",
    "pred = mode(np.stack(predictions), 0).mode.reshape(-1)\n",
    "\n",
    "# example of how to save a prediction\n",
    "np.savetxt('prediction2.csv', pred, delimiter=',', encoding='utf-8') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
